name: AQI Full Automation

on:
  schedule:
    # Run data pipeline hourly
    - cron: '0 * * * *'
    # Run training pipeline daily at 2 AM
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allows manual trigger

jobs:
  setup:
    name: Setup Python
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository with LFS
        uses: actions/checkout@v4
        with:
          lfs: true
          fetch-depth: 0

      - name: List files for debugging
        run: |
          pwd
          ls -R

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r AQI/aqi_feature_repo/requirements.txt

  data_pipeline:
    name: Run Data Pipeline
    needs: setup
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository with LFS
        uses: actions/checkout@v4
        with:
          lfs: true
          fetch-depth: 0

      - name: List files for debugging
        run: |
          pwd
          ls -R

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r AQI/aqi_feature_repo/requirements.txt

      - name: Run Data Pipeline
        run: python AQI/aqi_feature_repo/feature_repo/automate_pipeline_khi.py

      - name: Commit updated data & logs & CSVs
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add AQI/aqi_feature_repo/feature_repo/data/khi_air_quality_clean.parquet
          git add AQI/aqi_feature_repo/feature_repo/data/live_pipeline.log
          git add AQI/aqi_feature_repo/feature_repo/data/history.csv
          git add AQI/aqi_feature_repo/feature_repo/data/forecast.csv
          git commit -m "Update data, logs, and CSVs via GitHub Actions" || echo "No changes to commit"
          git push origin main

  model_training:
    name: Run Training Pipeline
    needs: setup
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository with LFS
        uses: actions/checkout@v4
        with:
          lfs: true
          fetch-depth: 0

      - name: List files for debugging
        run: |
          pwd
          ls -R

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r AQI/aqi_feature_repo/requirements.txt

      - name: Run Training Pipeline
        run: python AQI/aqi_feature_repo/feature_repo/model_train/train_pipeline.py

      - name: Commit updated models & CSVs
        run: |
          git lfs install
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add AQI/aqi_feature_repo/feature_repo/model_train/model_registry/*.pkl
          git add AQI/aqi_feature_repo/feature_repo/data/history.csv
          git add AQI/aqi_feature_repo/feature_repo/data/forecast.csv
          git commit -m "Update models and CSVs via GitHub Actions" || echo "No changes to commit"
          git push origin main

  deploy_streamlit:
    name: Deploy Streamlit (Optional/Manual)
    needs: setup
    if: github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Deploy Streamlit
        run: |
          echo "Streamlit deployment can be triggered manually here."
